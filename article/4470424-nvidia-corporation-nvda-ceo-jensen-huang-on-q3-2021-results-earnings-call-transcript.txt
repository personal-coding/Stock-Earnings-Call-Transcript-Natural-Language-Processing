NVIDIA Corporation (NASDAQ:NVDA) Q3 2021 Earnings Conference Call November 18, 2021 5:00 PM ET
Company Participants
Jensen Huang â President and Chief Executive Officer
Simona Jankowski â Vice President Investor Relations
Colette Kress â Executive Vice President and Chief Financial Officer
Conference Call Participants
Aaron Rakers â Wells Fargo
Mark Lipacis â Jefferies
C.J. Muse â Evercore ISI
Stacy Rasgon â Bernstein Research
Vivek Arya â BofA Securities
Timothy Arcuri â UBS
Operator
Good afternoon. My name is Sadie and I'll be your conference operator today. At this time, I would like to welcome everyone to the NVIDIA's Third Quarter Earnings Call. All lines have been placed on mute to prevent any background noise. After the speakers ' presentation, there will be a question-and-answer session. [Operator Instructions ] Thank you. Simona Jankowski, you may begin your conference.
Simona Jankowski
Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2022. With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer, and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter and fiscal year 2022. The content of today's call is NVIDIA's property. It can be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release. Our most recent forms,10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission.
All our statements are made as of today, November 17, 2021, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.
Colette Kress
Thanks, Simona. Q3 was an outstanding quarter with revenue of $7.1 billion and year-on-year growth of 50 %. We've set records for total revenue as well as for gaming, data center, and professional visualization. Starting with gaming, revenue of $3.2 billion was up 5 % sequentially, and up 42 % from a year earlier. Demand was strong across the board while we continue to increase desktop GPU supply. We believe channel inventories remain low. Laptop GPUs also posted strong year-on-year growth led by increased demand for high-end RTX laptops. NVIDIA RTX technology is driving our biggest upper refresh cycle with gamers and continues to expand our base with creators. RTX introduced ground breaking real-time ray-tracing and AI enabled super resolution capabilities, which are getting adopted at an accelerating pace. More than 200 games and applications now support NVIDIA RTX including 125 with NVIDIA DLSS. This quarter alone, 45 new game shipped with DLSS. An NVIDIA Reflex latency reducing technology is in top eSports titles, including Valorant, Fortnite, Apex Legends, and Overwatch. 
In addition, the Reflex ecosystem continues to grow, with Reflex technology now integrated in almost 50 gaming peripherals. NVIDIA Studio for creators keeps expanding. Last month at the Adobe MAX Creativity Conference, Adobe announced 2 powerful AI features for Adobe Lightroom and the Lightroom Classics, accelerated by NVIDIA RTX GPUs. In addition, several of our partners launched new studio systems, including Microsoft, HP, and ASUS. We estimate that 1/4 of our installed base has adopted RTX GPUs. Looking ahead, we expect continued upgrades as well as growth from NVIDIA GeForce users given rapidly expanding RTX support and the growing popularity of gaming, eSports, content creation, and streaming. Our GPUs are capable of cryptomining but we don't have visibility into how much this impacts our overall GPU demand. In Q3, nearly all of our Ampere architecture of gaming desktop GPU shipments were might hash rate to help steer G4 supply to tiers. Crypto mining processor revenue was $105 million, which is included in our own and other. Our cloud gaming service, GeForce Now has 2 major achievements this quarter. First, Electronic Arts brought more of its hit games true to service. And second, we announced a new GeForce Now RTX 3080 membership tier priced at less than $100 for 6 months. 
GeForce Now membership has more than doubled in this last year to over 14 million gamers that are streaming content from 30 Data Centers in more than 80 countries. Moving to pro visualization, Q3 revenue of $577 million was up 11 % sequentially, and up a 144 % from the year-ago performance. The sequential rise was led by mobile workstations with desktop workstations also growing, as enterprise deployed systems to support hybrid work environment. Building on the strong initial ramp in Q2 and pure architecture sales continue to grow. Leading verticals including media and entertainment, healthcare, public sector and automotive. Last week we announced general availability of Omniverse enterprise a platform for simulating physically accurate 3D world and digital [Indiscernible]. Initial market reception to Omniverse has been incredible. Professionals at over 700 companies are evaluating the platform including BMW, Ericsson, [Indiscernible] and Sony Pictures. 
More than 70,000 individual creators have downloaded Omniverse. Since the open beta launch in December. There are approximately 40 million 3D designers in the global market. Moving to Automotive. Q3 revenue of $135 million declined 11 % sequentially and increased 8 % from the year-ago quarter. The sequential decline was primarily driven by AI cockpit revenue, which has negatively been impacted by automotive manufacturers supplying consumers. We announced that self-driving truck start-up Kodiak Robotics, automaker Lotus, autonomous bus manufacturers QCraft, and EV startup, WM Motor, have adopted the NVIDIA DRIVE Orin platform for their next-generation vehicles. They join a large and rapidly growing list of companies adopting and developing on NVIDIA DRIVE, including auto OEMs, Tier 1 suppliers, NAVs, trucking companies, robotaxis, and software startups. Moving to data center, record revenue of $2.9 billion grew 24 % sequentially, and 55 % from the year-ago quarter, with record revenue across both hyperscale and vertical industries. 
Strong growth was led by hyperscale customers fueled by continued rapid adoption of Ampere Architecture Tensor Core GPUs, for both internal and external workloads. Hyperscale compute revenue doubled year-on-year, driven by the scale-out of natural language processing and recommend data models and cloud computing. Vertical industry growth was also strong, led by consumer Internet and broader cloud providers. For example, [Indiscernible] cloud deployed NVIDIA GPUs for its launch of AI services, such as tech analysis, speech recognition, computer vision, and anomaly protection. We continue to achieve exceptional growth in influence which again outpaced our overall days in growth. We have transitioned our lineup of instance focused processes to the Ampere architecture such as the [Indiscernible] GPU. We also released the latest version of our [Indiscernible] server software, enabling compute intensive, influenced workflows, such as large leverage models to scale across multiple GPUs and node with realtime performance. Over 25,000 companies worldwide use NVIDIA AI influence. 
A great new example is Microsoft Teams which has nearly 250 million monthly active users. It uses NVIDIA AI to convert speech to text real time during video calls in 28 languages in the cost of [Indiscernible]. We reached 3 milestones to help drive more mainstream enterprise adoption of NVIDIA AI. First, we announced the general availability of NVIDIA AI enterprise, our comprehensive software suite of AI tools and frameworks that enables the hundreds of thousands of companies running NVIDIA -- running the sphere to virtualize AI workloads on NVIDIA -Certified systems. Second, VMware announced a future update to the store with Tanzu that is fully optimized for NVIDIA AI. When it's combined with NVIDIA AI enterprise, enterprises can efficiently manage cloud native AI development and deployment on mainstream Data Centers photos and files with existing IT tools. And third, we expanded our LaunchPad program globally with econnect (ph) as our first digital infrastructure partner. NVIDIA LaunchPad is now available in 9 locations worldwide, providing enterprises with immediate access to NVIDIA's software and infrastructure to help them prototype and test data signs and Al workloads. LaunchPad features NVIDIA-Certified systems and NVIDIA DGX systems running the entire NVIDIA AI software style. In networking, revenue was impacted as demand outstripped supply. 
We saw momentum toward higher speed and new-generation products, including ConnectX-5 and 6. We announced the NVIDIA Quantum-2 400 gigabit per second end-to-end networking platform, consisting of the Quantum-2 switch to connect X-7 network adapter and the BlueField-3 -3 DPU. The NVIDIA Quantum-2 switch is available from a wide range of leading infrastructure and system vendors around the world. Earlier this week, the latest top 500 list of supercomputers showed continued momentum for our full staff computing approach. NVIDIA technologies accelerate over 70 % of the systems on the list including over 90 % of [Indiscernible] systems, and 23 of the top 25 most energy efficient systems. Turning to GTC, last week we hosted our GPU technology convent which had over 270,000 registered attendees. Jensen's keynote has been viewed 25 million times over the past 8 days. While our spring GTC focused on new chips and systems, this addition focused on software, demonstrating our full computing [Indiscernible]. Many cover some of the highlights. 
Our vision for Omniverse came to life at GTC. We significantly expanded its ecosystem and announced new capabilities. Omniverse Replicator is an engine for producing data to train robots. Replicator augments real -world data with massive, diverse, and physically accurate synthetic datasets to help accelerate development of high-quality, high-performance AI across computing demands. NVIDIA Omniverse Avatar is our platform for generating interactive AI avatars that connects several core NVIDIA SDKs including speech AI, computer vision, natural language understanding, recommendation engines, and simulation. Applications, including automated customer service, virtual collaboration, and content creation. Replicator, and Avatar joined several other announced features and capabilities for Omniverse, including AI, AR, VR and simulation-based technologies. We introduced 65 new and updated software development kits bringing our total to more than 150, serving industries from gaming and design, to AI, cybersecurity, 5G, and robotics. 1 of the SDKs is our first 4-license AI model, NVIDIA Riva, for building conversational AI applications. 
Companies usually rebound during the open beta, include RingCentral for video conference live captioning, and 10-ounce the customer service chat box. NVIDIA Riva Enterprise will be commercially available early next year for large-scale [Indiscernible] We introduced the NVIDIA NeMo Megatron framework, optimized for training large language models on NVIDIA DGX simplified infrastructure. This combination brings together production-ready enterprise-grade of hardware and software. Our vertical industries develop language and industry-specific chat box, [Indiscernible] systems, content generation, and summarization. Early adopters include CD, JD.com and VinBrain. We unveiled BlueField DOCA 1.2, the latest version of our DPU programming [Indiscernible] with new cyber security capabilities. DOCA is to our GPUs as [Indiscernible] is to our GPUs. It enables developers to build applications and services on top of our [Indiscernible] DPUs. Our near capabilities make BlueField the ideal platform for the industry to build their own zero-trust security platforms. The leading cybersecurity companies are working with us to provision their next-generation firewall service on BlueField, including checkpoint, Juniper for net, S5, file-to-network and VM1. 
And we released Clara Holoscan, an edge AI computing platform for medical instruments to improve decision-making tools in areas such as robo-assisted surgery, interventional radiology, and radiation therapy planning. Other new or expanded SDKs libraries unveiled at GDC include ReOpt for AI-optimized statistics, cuQuantum for quantum computing, Morpheus for cybersecurity, Modulus for physical face machine learning, and cuNumeric, a data center scale math library to bring accelerated computing to the large and growing Python ecosystem. All in, NVIDIA's computing platform continues to expand as a broadening set capacity pays enabled more and more GPU accelerated applications and industry useful sources. CUDA has been downloaded 30 million times, and our developer ecosystem is now nearing 3 million strong. The applications they develop on top of our SDKs, and the cloud edge computing platform are helping to trend [Indiscernible] multi-trillion dollar industries. 
From healthcare, to transportation, to purchase services, manufacturing, logistics and retail. In automotive, we announced NVIDIA DRIVE pumps years and drives [Indiscernible] AI software platforms that enhance a vehicle's performance, features, and safety. DRIVE Concierge, built on Omniverse Avatar, functions as an AI-based intelligent personal assistant, but enables automatic parking summoning capabilities. It also enhanced safety by monitoring the driver throughout the duration of the trip. Drive Chauffeur offers autonomous capabilities, relieving the driver of constantly having to control the car. It will also perform address-to-address driving when combined with DRIVE Hyperion 8 platform. For robotics, we announced Jetson AGX Orin for world's smallest, most powerful, and energy efficient AI supercomputer for robotics, autonomous machine, and embedded computing of the edge. Built on our Ampere architecture, Jetson AGX Orin provides 6x the processing power of its predecessor and delivers 200 trillion operations processor similar to a GPU-enabled server that fits into the palm of your hand. Jetson AGX Orin will be available in the first quarter of calendar 2022. 
Finally, we revealed plans to build Earth-2, the world's most powerful AI supercomputer dedicated to confronting climate change. The system would be the climate change of the product to Cambridge-1. The UK's most powerful AI super computer that we built for small scale research. Earth-2 furnishes all the technologies we have invented up to this moment. Let me discuss Arm. I will provide you a brief update on our proposed acquisition of Arm. Arm, with NVIDIA, is a great opportunity for the industry and customers. With NVIDIA 's scale, capabilities and robust understanding of datacenter computing, acceleration and AI ARM in expanding their reach into Data Center, IoT and PCs and advanced ARM's IP for decades to come. The combination of our companies can enhance competition in the industry as we work together on further building the world of AI. Regulators at the U.S. FTC have expressed concerns regarding the transaction when we are engaged in discussions with them regarding remedies to address those concerns. 
The transaction has been under review by China's antitrust authority, pending to formal case initiation. Regulators in the UK and the EU have declined to [Indiscernible] in phase 1 of the reviews on competition concerns. In the UK, they have also voiced national security concerns. We have begun the phase 2 process in the EU and UK jurisdiction. Despite these concerns and those raised by some ARM licensees, we continue to believe in the merits and the benefits of the acquisition to all -- of the acquisition to ARM, to its licensees, and the industry. We believe these concerns and those raised by some ARM licensees. We continue to believe in the merits and benefits of the ARM acquisition. Moving to the rest of the P&L, GAAP gross margin for the third quarter was up 260 basis points, from a year earlier, primarily due to [Indiscernible] mix within desktop, notebook, Geforce GPUs. Year-on-year increase also benefited from a reduced impact of acquisition related costs. GAAP gross margin was up 40 basis points sequentially driven by growth in our data center of Ampere Architecture products, which is particularly offset by net [Indiscernible]. 
Non-gaming gross margin was up a 150 basis points from a year earlier and up 30 basis points sequentially. Q3 GAAP EPS is $0.97. 83 % from a year earlier non-GAAP EPS was a $1.17 up 60 % from a year ago adjusting for our stocks [Indiscernible]. Q3 cash flow from operations was $1.5 billion up from $1.3 billion a year earlier, and down from $2.7 billion in the final quarter. The year-on-year increase primarily reflects higher operating income, particularly offset by prepayment for long-term supply agreement. Let me turn to the outlook for the fourth quarter of fiscal 2022. We expect sequential growth to be driven by datacenter and gaming more than offsetting a decline in CMP. Revenue is expected to be $7.4 billion, +/ - 2 %. GAAP and non-GAAP Gross margin are expected to be 65.3% and 67 % respectively, +/ - 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $2.02 billion and $1.43 billion respectively. GAAP and non-GAAP other income and expenses are both expected to be an expense of approximately $60 million, excluding gains and losses on non-affiliated investments. 
GAAP and non-GAAP tax rates are both expected to be 11 %, plus or minus 1 %, excluding discrete items. Capital expenditures are expected to be approximately $250 million to $275 million. Further financial details are included in the CFO Commentary. Other information is also available on our IR website. In closing, let me finalize upcoming events with the financial community We will be attending the Credit Suisse 25th Annual Technology Conference in person on November 30th. We'll also be at the Wells Fargo 5th Annual TMT Summit virtually on December 1st, the UBS Global TMT Virtual Conference on December 6th, and the Deutsche Bank Virtual AutoTech Conference on December 09. Our earnings call to discuss our fourth quarter and fiscal year 2022 results is scheduled for Wednesday, February 16th. With that, we will now open the call for questions. Operator, will you please poll for these questions.
Question-and-Answer Session
Operator
And at this time, I would like to remind everyone. [Operator's Instruction ] For our first question, you have Aaron Rakers from Wells Fargo. Aaron, your line is open.
Aaron Rakers
Thanks for taking the question, and congratulations on the results. I guess I wanted to ask about Omniverse, obviously a lot of excitement around that. I guess the simple question is, Jensen, how do you define success, in Omniverse as we look out over the next, let's call it 12 months? And how do we think about the subscription license opportunity for Omniverse? I know you've talked about 40 million total 3D designers. I think that actually doubled, what you talked about back in August. I'm just curious of how we as financial analysts should start to think about that opportunity materializing.
Jensen Huang
Thanks. Omniverse success will be defined by #1. Developer engagement connected with developers around the world, 2. Applications being developed by enterprises, 3. The connection of designers and creators among themselves. Those are the nearest term -- and I would say that in mind, type of a definitive success. Near-term also should be revenues and Omniverse has real immediate applications as I demonstrated at the keynote and I'll highlight a few of them right now. One of them, of course, is that it serves as a way to connect 3D and digital designing world. Think of Adobe as a world, think of Autodesk as a world, think of Rivet as a world, these are design world in the sense that people are doing things in it. They're creating things in it and it has its own database. We made it possible for these worlds to be connected, for the very first time. And for it to be shared like in cloud document. That's not been possible ever before. You can now share work with each other, you could see each other's work. You could collaborate. And so in a world of remote working, Omniverse's collaborative ability is going to be really appreciated, and that should happen right away. 
We would like to see that happen in very near terms. And that drives, of course, more PC sales, more GPU sales, more workstation sales, more server sales. The second use case is digital twins and you show -- you saw examples of how several companies that are seeing using Omniverse to create a digital twin of that city so that they could optimize radio placements and radio energy used for being forming. You saw BMW using it for their factories. You're going to see people using it for warehouse, logistics warehouse, to plan and to optimize their warehouses and to plan the robots. And so digital twin applications are absolutely immediate. And then remember robots has several clients. There's the physical robots that you saw and a physical robot with the self-driving cars. A physical robot could be the car itself turning into a robot so that it could be an intelligent assistant. I demonstrated probably the -- in my estimation, the largest application of robots in the future and it's avatars. 
We built Omniverse Avatar to make it easy for people to integrate some amazing technology. We'll consider vision with speed recognition, natural language understanding, gesture recognition, facial animation, speech synthesis, recommender systems. All of that integrated into 1 system and money in real, time that avatar's system is essentially a robotic system. And the way that you would use that is for example, the $25 million or so retail stores, restaurant, places like airports, train stations and office buildings and such where you can have intelligent avatars doing a lot of assistance. They might be doing checkout, they might be doing check in, they might be doing at customer support. And all of that can be done with avatars, as I've demonstrated. So the virtual, the virtual robotics application, digital vibes or avatars, it is going to be likely the largest robotics opportunity. So if you look at our licensing model, the way it basically works is that inside Omniverse, each 1 of the main users, and the main users could be one of the 20 million creators, or 20 million designers the 40 million creators and designers around the world when they share Omniverse, each one of the main users would be $1,000 per user per year. 
Don't forget that intelligent livings or intelligent users that are going to be connected to Omniverse, will likely be much larger as digital bots than human. So I'd mentioned 40 million, but there are 100 million cars. We've heard that the new cars will all have -- will all be -- have the capability to have something like an Omniverse Avatar. And so there's 100 million cars to be $1,000 per car per year. And in the case of 25 million or so places where you would have a digital Avatar as customers support or check out smart retail or smart warehouse or wherever it is, those Avatars are also -- would each individually be a new account, and so they would be $1000 per Avatar per year. And so, it's like -- those are the immediate tangible opportunities for us and I demonstrated the application during the keynote. And then of course, behind all of that, call it a couple of 100 million on a digital agents, intelligent agent, some of the interim for low by some of them avatars at $1,000 per agent, per year. Behind it, our immediate nvidia GPUs, DTC, and via GTS in the cloud, NVIDIA GPS servers. 
And minus,-- my guess would be the hardware part of it is probably going to be about half the licensing part of the card view about half will be timing. But this is really going to be one of the largest graphics opportunities that we've ever seen. And the reason why it's taking so long for it just to manifest is because it requires 3 fundamental technologies to come together, I guess, 4 fundamental technologies for it together. First of all this could be the graphics, second, is physics simulation, because we're talking about things in world that has to be believable. So it has to obey the laws of physics. And then third is artificial intelligence as I demonstrated. And all of it runs on top of a Omniverse computer that has to do not just AI, not just physics, not just computer graphics, but all of it. And so what long-term people -- why people are so excited about it is, at the highest level, what it basically means is that long-term when we engage the Internet, which is largely 2D today, long-term every query would be 3D. 
Instead of just querying information, we would query and interact with people, and Avatars, and planes, and places, and all of these things are in 3D. So hopefully, one of these days that we'll try to realize it as fast as we can, every transaction that goes over the Internet touches a GPU. And today that's a very small percentage but hopefully one of these days it'll be a fair bit of high percentage. I hope that's helpful.
Operator
Our next question we have Mark Lipacis from Jefferies. Mark, your line is open.
Mark Lipacis
Hi, thanks for taking my question. Jensen, it seems like every year there seems to be a new set of demand drivers for your accelerated processing ecosystem, there's gaming, then neural network in an AI, and then blockchain and the ray-tracing. And if the 5 or 6 years ago, you guys showed a bunch of virtual reality demos which were really exciting at your Analyst Day excitement down -- died down. Now it seems to be resurfacing seen particularly with Omniverse Avatar capability at Facebook shining a light on opportunity. So the 2 questions from that are, how close is your Omniverse Avatar took to morphing into like a mass market technology that everybody uses daily. If you can talk about -- like you said, that everybody is going to be a gamer. Everybody is going be used -- everybody is going to be a Omniverse Avatar, you said. And maybe the bigger picture is: Is it reasonable to think about new killer app coming out every year? Is there a parallel that we should think about with previous competing markets that we could think about for the computing era that we're entering right now? Thank you.
Jensen Huang
Yes, I really appreciate that. Chips are enablers, but just don't create markets, software creates market. I've explained over the years that accelerated computing is very different than channel purpose computing. The reason for that is because you can't just write a C compiler and compile quantum physics into a chip and it does it. You can't just compile a stranger's equation and have it distributed across multiple GPUs, multiple nodes that have it be fast. You can't do that with computer graphics, you can't do that for artificial intelligence, you can't do that for robotics, you can't do that for most of the interesting applications in the world. Because we really went out of theme with PCs that people are saying they're not because it's not true, it's abundantly clear that the amount and instruction level parables embedded can squeeze out of that system. It is, although not zero, is incredibly hard. It's just incredibly hard and there's another approach and we've been allocating. It's already confusing for some time and now people really see the benefit of it. But it does require a lot of work and the work basically says for every domain, for every application you have the [Indiscernible] in large domains, ideally. You have to have a whole staff. 
And so whenever you want to open a new market by accelerating those applications or their domain of application, you have to come up with new stack. And the new stack is hard because you have to understand the application, you have to understand the algorithms, the mathematics. You have to understand computer science to distribute across, to change something that was single threaded and make it multi-threaded, maybe something that would be done sequentially and make it positive in parallel. You break anybody, you break storage, you break networking, you break everything. And so it takes a fair amount of expertise and that's why we say that over the years, over nearly the course of 30 years, we've become a full-stack Company because we've been trying to solve this problem for practically 2 decades. And so that's 1. For the benefit, once you have an ability, then you can open new markets. And we played a very large role in demonetizing artificial intelligence and making it possible for anybody to be able to do it. We â 
Our greatest contribution is I hope when it's all said and done that we democratize scientific computing so that researchers and scientists, computer scientists, data scientists decided bulk night. We're able to get access to this incredibly harmful to order we call computers, to advancing search. And so every single year we're coming up with new stats and we got a whole bunch of size awarding on. And many of them I'm working on in plain sight. So that you see it coming, you just have to connect it together. 1 of the areas that we spoke about this time, of course, was Omniverse. You saw the pieces of it that we built over time. It took half a decade to start building Omniverse but it built on 1/4 of century of work. In the case of the Omniverse Avatar, you can literally point to Merlin the recommender, Megatron the language -- large language model, Riva the speech AI, all of our computer vision AIs that I've been demonstrating over the years. 
Natural speech synthesis that you see every single year with I Am AI, the opening credits. How we're using developing an AI to be able to speak in a human way so that people feel more comfortable and more engaged with the AI. Face, eye-tracking and all of these technologies all came together. They were all kept being built in pieces by the integrated -- the intentions of integrating it and to create what it's called Omniverse Avatar. And now you have to question how quickly will we deploy this? I believe Omniverse Avatar will be in drive-thrus of restaurants, fast food restaurants, checkouts of restaurant, in retail stores all over the world within less than 5 years. [Indiscernible] in all kinds of different application s because there is such a great shortage of labor and there's such a wonderful way that you can now engage an Avatar. It could -- it doesn't make mistakes, it never gets tired when it's always on. 
And we moved to the cloud native and so when you saw that we installed a key note I hope you'd agree that the interactions are [Indiscernible] and the conversational foreign is so enjoyable. And so anyway, I think what you highlighted in this one? It's already continues to full stack challenge, 2. It takes off with open new markets. new markets. If you build another chip, you could steal somebody's share, but you can't open new markets. And it takes software to open new market. Nvidia Switch with software and that's one of the reasons why we could engage with such large market opportunity. And then lastly, with respect to Omniverse, I believe it's a year term opportunity that we've been working on for some since before 5 years.
Operator
For our next question, we have C.J. Muse from Evercore ISI. C.J, our lines is open.
C.J. Muse
Yeah, good afternoon, and thank you for taking the question. And not an Omniverse question, but Jensen, I'd like your commitment that you will not use Omniverse to target the sell-side research industry. As my real question, can you speak to your data center visibility into 2022 and beyond? And within this outlook, can you talk to traditional cloud versus industry verticals, and then perhaps emerging opportunities like Omniverse and others. Would love to get a sense of kind of what you're seeing today, and then as part of that, how you're planning to secure foundry and other supply to support that growth. Thank you.
Jensen Huang
Thank you, C.J. First of all, we have secured guaranteed supply, very large amounts of it, quite a spectacular amount of it from the world's leading LED and substrate in packaging and testing companies. They are usually part of our supply chain and so, we have done that and a very good about our supply situation, particularly starting the second half of my share and going forward. I think this whole last year was a wake up call for everybody to be much more mindful about not taking this supply chain for granted when we were fortunate to have such great partners. But nonetheless, we've secured in our future. With respect to data center, about half of our incentive business comes from the cloud and cloud service providers and the others come s from Enterprise what we call Complete Enterprise Companyâs all in kinds of industries. And about 1 % of it comes from super-computing centers and consult with sort of 40 % of so cloud, 50 % on enterprise, and 1 % significantly resent. And we expect next year the cloud service providers to scale out their chip learning and their AI workload really aggressively. 
And we're seeing that right now. We built a really fantastic platform and number 1, number 2. The work we've been doing with potential RT which has the runtime that goes with the server that's called Triton. It's one of our best pieces of work, we're just so proud of it. We said nearly 4 years ago, 3.5 years ago, that if its going to be one of the great computer science challenger, really proving to be so. And the reason for that is because sometimes it's difficult, sometimes it's just latency, sometimes interactivity. And the type of models we yet to increase is just all over the math. It's not just considered vision what you need recognition and it's all over the internet, and in addition to that, something different types of architectures that are still need to find ways to build different applications and so the advocacy is complicated. This is a wonderful people working. We're now on our 8th generation on that is adopted all over the world from 25 thousand companies in video in L.A. And recently at VTC, we announced 2 very, very big thing. 
One we reminded everybody that just month before we had training support, not just in every generation of NVIDIA GPUs of which there are still many versions to be managing without trying how would you possibly deploy AI across the entire fleet of NVIDIA servers -- NVIDIA GPU servers that are all over the world. And so there's almost an essential tool. Just to take operate and take advantage of all of NVIDIA's GPUs [Indiscernible]. 2, we support GPUs and so it's no longer necessary for someone to have 2 influence servers. You can just have 1 influence server because the NVIDIA version already essential. Now, everybody could just use Triton in every, every futile server in a datacenter to be part of the inference capacity. and then we discussed the AI cell. It was a really big deal at GTC, which is called forest inference library, called FIL. 
So basically, the most popular machine learning system in inference models are based on trees and decision trees and boosted gradient trees and people might know it as XGBoost. [Indiscernible] the placing, fraud detection, in recommenders systems, and they're utilized by companies all over the world because it's just self-explanatory, you can build upon it, you don't worry about regressions if you build bigger and bigger trees. And we [Indiscernible] we announced that we support that as well. And so all of a sudden, all of that workload that runs on CPU is not only did it run on trading, it becomes accelerated. The last -- the next thing you will see as long with tremendous interest in margin on which models on Triton now also supports multi GPU on multi-mode inference, so that we can taste something like an OpenAI GPT -3 and NVIDIA Megatron 530B or anybody guy and model that's being developed all over the world. And all these different languages, and all these different demands, and these different fields as Brian is and what an industry where we can now influences in real-time. 
From now demonstrated it in one of the demos and builds in, was able to see basically your questions real-time. And so damaging for giant breakthrough means that these are the type of workloads that can make it possible for us to continue to scale out. Back to your original question, I think next year is going to be quite a good year for Data centers. Customers are very mindful of securing their supply for their scale-out and so we have the thermal on visibility and more visibility problems than ever of data centers, but in the recent event, try new adoptions everywhere. And then finally, are brand-new workload which is built on top and AI and glass and simulations with Omniverse and you saw the examples that I gave, these are real companies doing real work. And one of the areas that had severe shortages around the world as customers support. Just January, severe shortages all over the world And we think the answer is Omniverse Avatar. And it runs and Data centers. You could direct Omniverse Avatar to do drive views or retail checkout or customer service loans the ministry of Tokyo, attacking [Indiscernible], you can use it for Intel operating customer service, and we demonstrated with Mike C, we demonstrated how you can use even for video conferencing, and then lastly, we demonstrated how can you use Omniverse Avatar for Robotics. For example, to create a concierge what we will call Drive concierge for the call. [Indiscernible]. Omniverse Avatar is going to be a really exciting driver for enterprises next year. The next year is going to be a -- we're cleaning up [Indiscernible]
Operator
For our next question we have Stacy Rasgon from Bernstein Research. Stacy, your line is open.
Stacy Rasgon
Hi guys. Thanks for taking my questions. I wanted to ask the two of them on data center, both near-term and then maybe a little longer-term. On the near-term collect, you suggested guidance into Q4 will be driven by data center and gaming and you mentioned data center first, does that mean that a bigger it think it will help us like pass the contribution of ethos into Q4 and then into next year given the commentary for the last question, sound are you had a very 100 hundred, Again, it sounds like you've got like a very strong outlook for datacenter, both from hyperscale and Enterprise. If I look at sort of the implied guidance, we give our datacenter for you is probably likely to grow 50 % year-over-year in this fiscal year. Would it be crazy to think, given all those drivers, that it could grow by a similar amount next year as well? Like I should be thinking about that, given all of the drivers that you've been laying out.
Colette Kress
Thanks, Stacy, for the question. Let's first focus in terms of our guidance for Q4. Our statements that we made were, yes, about driven by revenue growth from data center and gaming sequentially. We could probably expect our data center to grow faster than our gaming, probably both in terms of percentage-wise and absolute dollars. We also expect our CMP product to decline quarter-on-quarter to very negligible levels in Q4. I hope that gives you a color on Q4. Now, in terms of next year, we'll certainly turn the corner into the new fiscal year. We certainly provide guidance one quarter out. We've given some great discussion here about the opportunities in front of us, opportunities with the hyper sales, the opportunities with the verticals. Omniverse is a full-stop opportunity in front of us. We are securing supply for next year, not just for the current year in Q4, to allow us to really grow into so much of this opportunity going forward. But at this time we're going to wait until next year to provide guidance.
Stacy Rasgon
That's helpful. Appreciate it. Thank you.
Operator
For the next question we have Vivek Arya from BofA Securities. Vivek, your line's open.
Vivek Arya
Thanks for taking my question, I actually had two quick ones. So, Colette you suggested the inventory purchase and supply agreements are up, I think almost 68 % year-on-year. Does that provide some directional correlation with how you are preparing for growth over the next 12 to 24 months? So that's one question. And then the bigger question, Jensen that I have for you is, where are we in the AI adoption cycles, what percentage of silvers are extend dated and hyperscaler and vertical industry today and where can those ratios get too?
Colette Kress
Thanks for the question. So let's first start in terms of supply or our supply purchase agreements. You have noted that we are discussing that we had made payments towards some of those commitments. Not only are we procuring for what we need in the quarter, what we need next year, and again, we are planning for growth next year. So we have been planning that supply purchases. We're also doing long-term supply purchases. These are areas of capacity agreements and or many of our different suppliers. We made a payment within this quarter of approximately $1.6 billion or the total long-term capacity agreement of about $3.4 billion. So we still have more payments to make and we will likely continue to be purchasing longer-term to support our growth that we are planning for many years to come.
Jensen Huang
Every single server will be Q2 accelerated some day. Today, of all the clouds and all the enterprise, less than 10 %. That kind of gives you a sense of where you are. In terms of the workloads, it is also consistent with that in the sense that a lot of the workloads still only run on GPUs, and which is the reason why in order for us to grow, we have to be a full-stack Company and we have to go find applications; we know the final is 20 of them, focus on applications that require exhilaration or benefits tremendously from exhilaration that is if they would to get 1 million x feet up, which sounds insane but it's not. Mathematically I can prove it to you, and historically I can demonstrate to you that in many areas we have seen million at [Indiscernible] has completely revolutionized those industries. Computer graphics is of course one of them. Omniverse would not be possible without it. So on work that we do with digital biology, proteins synthesis, which is likely going to be one of the large industries in the world but doesn't exist today at all. 
Protein engineering and the protein economy is likely going to be very large. You can't do that unless you are able to get a million speed up in simulations of protein dynamics. And so -- not to mention some of the most imperative comps we have growth and engage clinical needs a million notes. music know you might deal with next year. We're at a point where we can action tabular. And so in each one new cases we have performing, we have the focus on resources to grow, accelerate those applications and that translates to growth. Until then they [Indiscernible] and if you look at a lot of today, each synthesis and speech recognition systems. still uses a fairly traditional or mixture of traditional and deep learning approaches for [Indiscernible]. NVIDIA believe that it's the world first, I believe that is ended in deep neural networks. 
And we worked with many companies in helping them advance theirs so that they could move their clouds to a neural based approaches. That's one of the reasons why we do it, so that we think we can provide you a record but we can also licenses to enterprises around the world for the good of that because the owners pieces. And so one application after another one, you have to get it accelerated 1 domain optimizing the mix solid. One of the ones that are worth very excited about in something we've been working on for so long as EDA even our own industry, electronic design automation, for the very first time you announced the EDA using [Indiscernible] computing or whether it's because the artificial intelligence facility, because EDA is a very large combinatorial optimization [Indiscernible]. And using artificial intelligence, you could really include the design quality and design timing. 
So it was the -- from all the major EDA vendors, from cheap designs to simulation to PCB design and optimization of designing synthesis. Moving towards artificial intelligence in GPU acceleration in a very significant way. And then we see that with mechanical CAD and traditional CAD application. Now also jumping on to GTC acceleration in getting very significant feed backs. And so I'm super excited about the work that we're doing in each one of these domains. Because every time you do it, you open up brand-new markets and customers are never used in the energy viewers. Now can because -- because ultimately problem and without a full fact without software Suky is really net the enabling technology which was a chip, provides oil-field resulting from.
Operator
Your final question comes from the line of Timothy Arcuri from UBS. Timothy your line is open.
Timothy Arcuri
Thanks a lot. Colette I have question about gross margin. Are there any margin headwinds, maybe on the wafer pricing side that we should sort of think about normalizing out? Because gross margins pretty flat between fiscal Q4 to fiscal Q2 -- sorry, between fiscal Q2 and fiscal Q4. But I imagine that's kind of masking a strong underlying margin growth especially as data centers been actually driving that growth. So I'm wondering if maybe there are some underlying factors that are sort of getting gross margins. Thanks.
Colette Kress
Yeah. So we have always been working on our gross margin and being able to absorb a lot of the cost changes along the way, architecture-to-architecture, year-to-year. So that's always based in to our gross margins. Our gross margins right now are largely stable. Our incremental revenue, for example, what we're expecting next quarter will likely align to our current gross margin levels that we finished in terms of Q3. Our largest driver always continues to be mixed. We have a lot of different mix related to high-end AI and RTX solutions, for example. And the software making better than solutions has allowed us to increase our gross margin. As we look forward long-term software is sold separately. May be another driver. Gross margin increases in the new future. But cost changes, cost increases have generally been a part of our gross margins for years.
Operator
Thank you. I will now turn the call over back to Jensen Huang for closing remarks.
Jensen Huang
Thank you. We had an outstanding quarter. Demand for NVIDIA AI is strong, with hyperscalers and cloud services deploying at scale and enterprises broadening adoption. We now count more than 25,000 companies that are using NVIDIA AI. And with NVIDIA AI enterprise software suite, our collaboration with VMware, and our collaboration with Equinix deploy NVIDIA LaunchPad across the world, every enterprise has an easy on-ramp to NVIDIA AI. Gaming and ProBiz are surging. RTX opportunity continues to expand with the growing markets of gamers, creators, designers, and now professionals building home workstations. We are working hard to increase supply for the overwhelming demand this holiday season. Last week, GTC showcased the expanding universe of NVIDIA-accelerated computing. In combination with AI and data center scale computing. The model we pioneered is on the cost of producing million X speed ups that will revolutionize many important fields. Already, AI and upcoming robotic digital biology, and what I hope on science. GPC highlighted our full-stack expertise in action. Built on tutor In our acceleration library in data processing, simulation, graphics, artificial intelligence, market, and delayed specific software is needed to solve customer problems. We also showed gross software opens new growth opportunities for us. 
As the cheaper the enablers for it's the software that opens new growth opportunities. NVIDIA has a 150 SDKs now, addressing many of the world's largest end markets. One of the major themes of this GTC was Omniverse. Our simulation platform for virtual worlds and digital tools. Our body of work and expertise in graphics, physics stimulation, AI, robotics and full stack computing made Omniverse possible. At GTC, we shared her Omniverse w as used to reinvent collaborative design, customer service Avatars and video conferencing and [Indiscernible] of factories, processing plants and even higher scheme. This is just the tip of iceberg of what's to come. We look forward to updating you on our progress next quarter. Thank you.
Operator
Thank you. I will now turn over to Jensen for closing remarks.
Colette Kress
Well, I think we just heard the closing remarks. Thank you so much for joining us. We look forward to seeing everybody of the conferences that we have planned over the next few months. And I'm sure we'll talk before the end of next earnings. Thanks again, everybody.
Operator
This concludes today's conference call. Thank you all for participating. You may now disconnect.
